{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 103,
   "outputs": [],
   "source": [
    "from sklearn.datasets import _california_housing\n",
    "\n",
    "data, target = _california_housing.fetch_california_housing(as_frame=True, return_X_y=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data_train, data_test, target_train, target_test = train_test_split(data, target, test_size=0.2, random_state=44)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Base"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn [90], line 5\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01msklearn\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mensemble\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m AdaBoostRegressor, HistGradientBoostingRegressor\n\u001B[0;32m      3\u001B[0m model \u001B[38;5;241m=\u001B[39m AdaBoostRegressor(random_state\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m69\u001B[39m, learning_rate\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m,n_estimators\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m100\u001B[39m, base_estimator\u001B[38;5;241m=\u001B[39mHistGradientBoostingRegressor(learning_rate\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0.1\u001B[39m, max_iter\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1000\u001B[39m, max_depth\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m8\u001B[39m, warm_start\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m, max_leaf_nodes\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, max_bins\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m255\u001B[39m))\n\u001B[1;32m----> 5\u001B[0m _ \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtarget_train\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\Documents\\Python\\Python311\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:1090\u001B[0m, in \u001B[0;36mAdaBoostRegressor.fit\u001B[1;34m(self, X, y, sample_weight)\u001B[0m\n\u001B[0;32m   1084\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m   1085\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mloss must be \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mlinear\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m, \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124msquare\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m, or \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mexponential\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   1086\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m Got \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mloss\u001B[38;5;132;01m!r}\u001B[39;00m\u001B[38;5;124m instead.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   1087\u001B[0m     )\n\u001B[0;32m   1089\u001B[0m \u001B[38;5;66;03m# Fit\u001B[39;00m\n\u001B[1;32m-> 1090\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msample_weight\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\Documents\\Python\\Python311\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:160\u001B[0m, in \u001B[0;36mBaseWeightBoosting.fit\u001B[1;34m(self, X, y, sample_weight)\u001B[0m\n\u001B[0;32m    156\u001B[0m random_state \u001B[38;5;241m=\u001B[39m check_random_state(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mrandom_state)\n\u001B[0;32m    158\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m iboost \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mn_estimators):\n\u001B[0;32m    159\u001B[0m     \u001B[38;5;66;03m# Boosting step\u001B[39;00m\n\u001B[1;32m--> 160\u001B[0m     sample_weight, estimator_weight, estimator_error \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_boost\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    161\u001B[0m \u001B[43m        \u001B[49m\u001B[43miboost\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msample_weight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mrandom_state\u001B[49m\n\u001B[0;32m    162\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    164\u001B[0m     \u001B[38;5;66;03m# Early termination\u001B[39;00m\n\u001B[0;32m    165\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m sample_weight \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "File \u001B[1;32m~\\Documents\\Python\\Python311\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:1152\u001B[0m, in \u001B[0;36mAdaBoostRegressor._boost\u001B[1;34m(self, iboost, X, y, sample_weight, random_state)\u001B[0m\n\u001B[0;32m   1150\u001B[0m X_ \u001B[38;5;241m=\u001B[39m _safe_indexing(X, bootstrap_idx)\n\u001B[0;32m   1151\u001B[0m y_ \u001B[38;5;241m=\u001B[39m _safe_indexing(y, bootstrap_idx)\n\u001B[1;32m-> 1152\u001B[0m \u001B[43mestimator\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX_\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1153\u001B[0m y_predict \u001B[38;5;241m=\u001B[39m estimator\u001B[38;5;241m.\u001B[39mpredict(X)\n\u001B[0;32m   1155\u001B[0m error_vect \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mabs(y_predict \u001B[38;5;241m-\u001B[39m y)\n",
      "File \u001B[1;32m~\\Documents\\Python\\Python311\\Lib\\site-packages\\sklearn\\ensemble\\_hist_gradient_boosting\\gradient_boosting.py:606\u001B[0m, in \u001B[0;36mBaseHistGradientBoosting.fit\u001B[1;34m(self, X, y, sample_weight)\u001B[0m\n\u001B[0;32m    589\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m k \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mn_trees_per_iteration_):\n\u001B[0;32m    590\u001B[0m     grower \u001B[38;5;241m=\u001B[39m TreeGrower(\n\u001B[0;32m    591\u001B[0m         X_binned\u001B[38;5;241m=\u001B[39mX_binned_train,\n\u001B[0;32m    592\u001B[0m         gradients\u001B[38;5;241m=\u001B[39mg_view[:, k],\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    604\u001B[0m         n_threads\u001B[38;5;241m=\u001B[39mn_threads,\n\u001B[0;32m    605\u001B[0m     )\n\u001B[1;32m--> 606\u001B[0m     \u001B[43mgrower\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgrow\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    608\u001B[0m     acc_apply_split_time \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m grower\u001B[38;5;241m.\u001B[39mtotal_apply_split_time\n\u001B[0;32m    609\u001B[0m     acc_find_split_time \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m grower\u001B[38;5;241m.\u001B[39mtotal_find_split_time\n",
      "File \u001B[1;32m~\\Documents\\Python\\Python311\\Lib\\site-packages\\sklearn\\ensemble\\_hist_gradient_boosting\\grower.py:360\u001B[0m, in \u001B[0;36mTreeGrower.grow\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    358\u001B[0m \u001B[38;5;124;03m\"\"\"Grow the tree, from root to leaves.\"\"\"\u001B[39;00m\n\u001B[0;32m    359\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msplittable_nodes:\n\u001B[1;32m--> 360\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msplit_next\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    362\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_apply_shrinkage()\n",
      "File \u001B[1;32m~\\Documents\\Python\\Python311\\Lib\\site-packages\\sklearn\\ensemble\\_hist_gradient_boosting\\grower.py:558\u001B[0m, in \u001B[0;36mTreeGrower.split_next\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    553\u001B[0m tic \u001B[38;5;241m=\u001B[39m time()\n\u001B[0;32m    554\u001B[0m smallest_child\u001B[38;5;241m.\u001B[39mhistograms \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhistogram_builder\u001B[38;5;241m.\u001B[39mcompute_histograms_brute(\n\u001B[0;32m    555\u001B[0m     smallest_child\u001B[38;5;241m.\u001B[39msample_indices\n\u001B[0;32m    556\u001B[0m )\n\u001B[0;32m    557\u001B[0m largest_child\u001B[38;5;241m.\u001B[39mhistograms \u001B[38;5;241m=\u001B[39m (\n\u001B[1;32m--> 558\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mhistogram_builder\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcompute_histograms_subtraction\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    559\u001B[0m \u001B[43m        \u001B[49m\u001B[43mnode\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mhistograms\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msmallest_child\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mhistograms\u001B[49m\n\u001B[0;32m    560\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    561\u001B[0m )\n\u001B[0;32m    562\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtotal_compute_hist_time \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m time() \u001B[38;5;241m-\u001B[39m tic\n\u001B[0;32m    564\u001B[0m tic \u001B[38;5;241m=\u001B[39m time()\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostRegressor, HistGradientBoostingRegressor\n",
    "\n",
    "model = AdaBoostRegressor(random_state=69, learning_rate=1,n_estimators=100, base_estimator=HistGradientBoostingRegressor(learning_rate=0.1, max_iter=1000, max_depth=8, warm_start=True, max_leaf_nodes=None, max_bins=255))\n",
    "\n",
    "_ = model.fit(data_train, target_train)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(\"R2 : \"+str(model.score(data_test, target_test)*100))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Search"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [],
   "source": [
    "def modelfit(alg):\n",
    "    alg.fit(data_train, target_train)\n",
    "    print(\"R2 : \"+str(alg.score(data_test, target_test)*100))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### HistGradientBoost"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 : 85.27182278562134\n"
     ]
    }
   ],
   "source": [
    "model = HistGradientBoostingRegressor(\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "modelfit(model)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_iter': 320}\n",
      "85.73089958108504\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "model = HistGradientBoostingRegressor(\n",
    "    random_state=42,\n",
    "    min_samples_leaf=20,\n",
    "    max_depth=12,\n",
    "    learning_rate=0.1,\n",
    ")\n",
    "\n",
    "\n",
    "parameters = {\n",
    "    'max_iter':range(200,501,10),\n",
    "}\n",
    "\n",
    "clf = GridSearchCV(estimator=model, param_grid=parameters)\n",
    "\n",
    "_ = clf.fit(data_train, target_train)\n",
    "print(clf.best_params_)\n",
    "print(clf.score(data_test, target_test)*100)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 22, 'min_samples_leaf': 60}\n",
      "86.00677194467193\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "model = HistGradientBoostingRegressor(\n",
    "    random_state=42,\n",
    "    max_iter=320,\n",
    "    learning_rate=0.1,\n",
    ")\n",
    "\n",
    "\n",
    "parameters = {\n",
    "    'min_samples_leaf':range(50, 121, 10),\n",
    "    'max_depth':range(20,28,2),\n",
    "}\n",
    "\n",
    "clf = GridSearchCV(estimator=model, param_grid=parameters)\n",
    "\n",
    "_ = clf.fit(data_train, target_train)\n",
    "print(clf.best_params_)\n",
    "print(clf.score(data_test, target_test)*100)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 : 86.00677194467193\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "model = HistGradientBoostingRegressor(\n",
    "    random_state=42,\n",
    "    max_depth=22,\n",
    "    min_samples_leaf=60,\n",
    "    max_iter=320,\n",
    "    learning_rate=0.1,\n",
    "    warm_start=True\n",
    ")\n",
    "\n",
    "\n",
    "modelfit(model)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Ada Boost"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 : 86.33181791549855\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "\n",
    "m = AdaBoostRegressor(random_state=42\n",
    "                      , base_estimator=model)\n",
    "modelfit(m)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "m = AdaBoostRegressor(random_state=42\n",
    "                      , base_estimator=model)\n",
    "\n",
    "parameters = {\n",
    "    'n_estimators':[10],\n",
    "}\n",
    "\n",
    "clf = GridSearchCV(estimator=m, param_grid=parameters)\n",
    "\n",
    "_ = clf.fit(data_train, target_train)\n",
    "print(clf.best_params_)\n",
    "print(clf.score(data_test, target_test)*100)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
