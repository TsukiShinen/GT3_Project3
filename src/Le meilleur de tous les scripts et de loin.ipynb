{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports\n",
    "\n",
    "# +------------+\n",
    "#  SUUUUUUUUUUU\n",
    "# +------------+\n",
    "\n",
    "#Imports\n",
    "import os\n",
    "import time\n",
    "import joblib\n",
    "from tqdm import tqdm\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.datasets import _california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import *\n",
    "from sklearn.ensemble import *\n",
    "\n",
    "from sklearn.model_selection import learning_curve\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "#Settings\n",
    "plt.style.use('dark_background')\n",
    "\n",
    "#Colonnes du dataset\n",
    "\"\"\"\n",
    "- MedInc        median income in block group\n",
    "- HouseAge      median house age in block group\n",
    "- AveRooms      average number of rooms per household\n",
    "- AveBedrms     average number of bedrooms per household\n",
    "- Population    block group population\n",
    "- AveOccup      average number of household members\n",
    "- Latitude      block group latitude\n",
    "- Longitude     block group longitude\n",
    "- MedHouseVal   median house value\n",
    "\"\"\"\n",
    "\n",
    "#Creation du dataframe avec le dataset\n",
    "df = _california_housing.fetch_california_housing(as_frame=True).frame\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Variables\n",
    "\n",
    "#Definition de la target\n",
    "target_name = \"MedHouseVal\"\n",
    "target = df[target_name]\n",
    "\n",
    "#Colonnes exclues pour le test\n",
    "columns_to_drop = [\n",
    "    target_name, \n",
    "    # \"Population\", \n",
    "    # \"AveOccup\", \n",
    "    # \"AveBedrms\", \n",
    "    # \"HouseAge\", \n",
    "    # \"AveRooms\"\n",
    "]\n",
    "data = df.drop(columns=columns_to_drop)\n",
    "\n",
    "#Modeles a tester\n",
    "models = [\n",
    "    AdaBoostRegressor(),  \n",
    "    BaggingRegressor(n_jobs=-1), \n",
    "    ExtraTreesRegressor(n_jobs=-1), \n",
    "    GradientBoostingRegressor(), \n",
    "    RandomForestRegressor(n_jobs=-1), \n",
    "    HistGradientBoostingRegressor()\n",
    "]\n",
    "\n",
    "linear_models = [\n",
    "    LinearRegression(),\n",
    "    Ridge(),\n",
    "    RidgeCV(),\n",
    "    SGDRegressor(),\n",
    "    Lasso(),\n",
    "]\n",
    "\n",
    "models_boost = [\n",
    "    #AdaBoostRegressor(base_estimator=BaggingRegressor(n_jobs=-1)),\n",
    "    #AdaBoostRegressor(base_estimator=ExtraTreesRegressor(n_jobs=-1)),\n",
    "    #AdaBoostRegressor(base_estimator=GradientBoostingRegressor()),\n",
    "    #AdaBoostRegressor(base_estimator=RandomForestRegressor(n_jobs=-1)),\n",
    "    AdaBoostRegressor(random_state=69, learning_rate=1,n_estimators=115, base_estimator=HistGradientBoostingRegressor(learning_rate=0.1, max_iter=1000, max_depth=7, warm_start=True, max_leaf_nodes=None, random_state=69,  max_bins=255)),\n",
    "\n",
    "    #BaggingRegressor(base_estimator=BaggingRegressor(n_jobs=-1)),\n",
    "    #BaggingRegressor(base_estimator=ExtraTreesRegressor(n_jobs=-1)),\n",
    "    #BaggingRegressor(base_estimator=GradientBoostingRegressor()),\n",
    "    #BaggingRegressor(base_estimator=RandomForestRegressor(n_jobs=-1)),\n",
    "    #BaggingRegressor(base_estimator=HistGradientBoostingRegressor()),\n",
    "]\n",
    "\n",
    "#Nombre de training par modele\n",
    "attemps = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fonctions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Traitement des donnees\n",
    "\n",
    "def TestModel(models):\n",
    "    global attemps\n",
    "    \n",
    "    #Initialisation de la dataframe des resultats\n",
    "    result_df = pd.DataFrame(columns=[\"ModelName\",\"AvgScore\",\"MaxScore\",\"AvgExecTime\"])\n",
    "\n",
    "    for model in models:\n",
    "\n",
    "        #Affichage\n",
    "        model_name = model.__class__.__name__\n",
    "        print(f\"{model_name}\")\n",
    "\n",
    "        #Initialisation des listes\n",
    "        score_results = []\n",
    "        time_results = []\n",
    "        \n",
    "        for i in tqdm(range(attemps)):\n",
    "\n",
    "            #Demarrage du timer\n",
    "            start = time.time()\n",
    "\n",
    "            #Split et Fit\n",
    "            data_train, data_test, target_train, target_test = train_test_split(data, target, test_size=0.20, random_state=69)\n",
    "            model.fit(data_train, target_train)\n",
    "\n",
    "            with open(\"IA.joblib\", \"wb\") as fo:\n",
    "                joblib.dump(model, fo)\n",
    "\n",
    "            #Calcul du score\n",
    "            score = model.score(data_test, target_test)\n",
    "\n",
    "            #Sauvegarde des resultats dans les listes\n",
    "            score_results.append(score)\n",
    "            time_results.append(time.time() - start)\n",
    "\n",
    "        #Calcul des stats\n",
    "        avg_score = round(np.average(score_results) * 100, 3)\n",
    "        max_score = round(np.max(score_results) * 100, 3)\n",
    "        avg_time = round(np.average(time_results), 3)\n",
    "\n",
    "        #Sauvegarde des resultats dans la dataframe\n",
    "        new_row = pd.DataFrame([[model_name, avg_score, max_score, avg_time]], columns=[\"ModelName\",\"AvgScore\",\"MaxScore\",\"AvgExecTime\"])\n",
    "        result_df = pd.concat([result_df, new_row])\n",
    "\n",
    "    #Affichage\n",
    "    print(f\"-\"*62, \"\\nResults :\")\n",
    "    print(result_df.to_string(index=False))\n",
    "    print(f\"-\"*62)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Learning Curve (Subplots MatPlotLib)\n",
    "\n",
    "def subplots_learnings_curves(\n",
    "    models,\n",
    "    data,\n",
    "    target\n",
    "):\n",
    "    plt.figure(1)\n",
    "    n_jobs = -1\n",
    "    fig, graphs = plt.subplots(1, len(models), figsize=(5* len(models), 5))\n",
    "    points_amount = 10\n",
    "    train_score_arr = []\n",
    "    test_scores_arr = []\n",
    "\n",
    "    for i in tqdm(range(len(models))):\n",
    "        graphs[i].set_title(models[i].__class__.__name__)\n",
    "        graphs[i].set_xlabel(\"Training examples\")\n",
    "        graphs[i].set_ylabel(\"Score\")\n",
    "        \n",
    "        train_sizes, train_scores, test_scores = learning_curve(\n",
    "        estimator = models[i],\n",
    "        X=data,\n",
    "        y=target,\n",
    "        n_jobs=n_jobs,\n",
    "        train_sizes=np.linspace(0.1, 1, points_amount)\n",
    "        )\n",
    "\n",
    "        train_scores_mean = np.mean(train_scores, axis=1)\n",
    "        test_scores_mean = np.mean(test_scores, axis=1)\n",
    "\n",
    "        train_score_arr.append(train_scores_mean)\n",
    "        test_scores_arr.append(test_scores_mean)\n",
    "\n",
    "    \n",
    "\n",
    "    for i in range(len(train_score_arr)):\n",
    "        graphs[i].set_ylim(np.min(test_scores_arr),1.2)\n",
    "        graphs[i].plot(train_sizes, train_score_arr[i])\n",
    "        graphs[i].plot(train_sizes, test_scores_arr[i])\n",
    "        graphs[i].legend(labels=[\"train\", \"test\"], loc=\"lower right\")\n",
    "\n",
    "    return plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoostRegressor\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [09:55<00:00, 595.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------- \n",
      "Results :\n",
      "        ModelName  AvgScore  MaxScore  AvgExecTime\n",
      "AdaBoostRegressor     85.09     85.09      595.676\n",
      "--------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#Call Traitement des donnees\n",
    "\n",
    "#TestModel(models)\n",
    "#TestModel(linear_models)\n",
    "TestModel(models_boost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Call Learning Curve (Subplots MatPlotLib)\n",
    "\n",
    "subplots_learnings_curves(\n",
    "    models_boost, \n",
    "    data,\n",
    "    target\n",
    ")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#IA\n",
    "with open(\"IA.joblib\", \"rb\") as fo:\n",
    "    cf = joblib.load(fo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Predicted  Original     Ecart\n",
      "0       4.447169     4.526  0.078831\n",
      "1       3.635930     3.585  0.050930\n",
      "2       4.534232     3.521  1.013232\n",
      "3       3.469839     3.413  0.056839\n",
      "4       3.316784     3.422  0.105216\n",
      "...          ...       ...       ...\n",
      "20635   0.734763     0.781  0.046237\n",
      "20636   0.829218     0.771  0.058218\n",
      "20637   0.871434     0.923  0.051566\n",
      "20638   0.903478     0.847  0.056478\n",
      "20639   0.911678     0.894  0.017678\n",
      "\n",
      "[20640 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "supatestodataframu = df.drop(columns=columns_to_drop)\n",
    "\n",
    "predicted = cf.predict(supatestodataframu)\n",
    "d = {'Predicted': predicted, 'Original': df['MedHouseVal'], 'Ecart': np.absolute(predicted-df['MedHouseVal'])}\n",
    "supa_resulto_dataframu = pd.DataFrame(data=d)\n",
    "\n",
    "print(supa_resulto_dataframu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.77411563561958\n",
      "11719.51472900916\n",
      "8263.800088534246\n"
     ]
    }
   ],
   "source": [
    "print(np.min(supa_resulto_dataframu[\"Ecart\"])*100000)\n",
    "print(np.average(supa_resulto_dataframu[\"Ecart\"])*100000)\n",
    "print(np.median(supa_resulto_dataframu[\"Ecart\"])*100000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b37f6842cfa5693682ca177646b86562e7e6680399d6aa97975ae5063d95e764"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
