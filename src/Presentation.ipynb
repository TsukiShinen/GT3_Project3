{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports & Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports\n",
    "\n",
    "import os\n",
    "import time\n",
    "import joblib\n",
    "from tqdm import tqdm\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "#Linear models\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import RidgeCV\n",
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "#Ensemble models\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.ensemble import BaggingRegressor\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor\n",
    "\n",
    "#Other models\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "#Sklearn\n",
    "from sklearn.datasets import _california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import learning_curve\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "#Settings\n",
    "plt.style.use('dark_background')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Variables\n",
    "\n",
    "#Creation du dataframe avec le dataset\n",
    "dataset = _california_housing.fetch_california_housing(as_frame=True)\n",
    "df = dataset.frame\n",
    "\n",
    "#Definition de la target\n",
    "target_name = \"MedHouseVal\"\n",
    "target = df[target_name]\n",
    "\n",
    "#Colonnes exclues pour le test\n",
    "columns_to_drop = [\n",
    "    target_name, \n",
    "    # \"Population\", \n",
    "    # \"AveOccup\", \n",
    "    # \"AveBedrms\", \n",
    "    # \"HouseAge\", \n",
    "    # \"AveRooms\"\n",
    "]\n",
    "data = df.drop(columns=columns_to_drop)\n",
    "\n",
    "\n",
    "data, target = _california_housing.fetch_california_housing(as_frame=True, return_X_y=True)\n",
    "#Split\n",
    "data_train, data_test, target_train, target_test = train_test_split(data, target, test_size=0.2, random_state=69)\n",
    "\n",
    "#Modèles à tester\n",
    "linear_models = [\n",
    "    LinearRegression(),\n",
    "    Ridge(random_state=69),\n",
    "    RidgeCV(),\n",
    "    Lasso(random_state=69),\n",
    "]\n",
    "\n",
    "ens_models = [\n",
    "    AdaBoostRegressor(random_state=69),  \n",
    "    BaggingRegressor(random_state=69, n_jobs=-1), \n",
    "    ExtraTreesRegressor(random_state=69, n_jobs=-1), \n",
    "    GradientBoostingRegressor(random_state=69), \n",
    "    RandomForestRegressor(random_state=69, n_jobs=-1), \n",
    "    HistGradientBoostingRegressor(random_state=69)\n",
    "]\n",
    "\n",
    "boost_and_bag_models = [\n",
    "    AdaBoostRegressor(base_estimator=BaggingRegressor(random_state=69, n_jobs=-1)),\n",
    "    AdaBoostRegressor(base_estimator=ExtraTreesRegressor(random_state=69, n_jobs=-1)),\n",
    "    AdaBoostRegressor(base_estimator=GradientBoostingRegressor(random_state=69)),\n",
    "    AdaBoostRegressor(base_estimator=RandomForestRegressor(random_state=69, n_jobs=-1)),\n",
    "    AdaBoostRegressor(base_estimator=HistGradientBoostingRegressor(random_state=69)),\n",
    "\n",
    "    BaggingRegressor(base_estimator=BaggingRegressor(random_state=69, n_jobs=-1)),\n",
    "    BaggingRegressor(base_estimator=ExtraTreesRegressor(random_state=69, n_jobs=-1)),\n",
    "    BaggingRegressor(base_estimator=GradientBoostingRegressor(random_state=69)),\n",
    "    BaggingRegressor(base_estimator=RandomForestRegressor(random_state=69, n_jobs=-1)),\n",
    "    BaggingRegressor(base_estimator=HistGradientBoostingRegressor(random_state=69)),\n",
    "]\n",
    "\n",
    "# AdaBoostRegressor(random_state=69, learning_rate=1,n_estimators=115, base_estimator=HistGradientBoostingRegressor(random_state=69, learning_rate=0.1, max_iter=1000, max_depth=7, warm_start=True, max_leaf_nodes=None))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I - Début de l'analyse des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Infos du dataset\n",
    "\n",
    "print(dataset.DESCR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Heatmap\n",
    "\n",
    "data = df.drop(columns=[\"Latitude\", \"Longitude\"])\n",
    "plt.figure(figsize=(12,7))\n",
    "sns.heatmap(data.corr(),cbar=True,annot=True,cmap='Blues')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prix moyen en fonction de l'age des maisons\n",
    "\n",
    "sns.lineplot(df,\n",
    "                x=\"HouseAge\", y=\"MedHouseVal\", alpha=0.5)\n",
    "plt.title(\"MedHouseVal based on HouseAge\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prix moyen en fonction du nombre de pièces\n",
    "\n",
    "sns.lineplot(df,\n",
    "                x=\"AveBedrms\", y=\"MedHouseVal\", alpha=0.5)\n",
    "plt.title(\"MedHouseVal based on AveRooms\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prix moyen en fonction de la localisation géographique\n",
    "\n",
    "sns.scatterplot(df,\n",
    "                x=\"Longitude\", y=\"Latitude\",\n",
    "                size=\"MedHouseVal\", hue=\"MedHouseVal\",\n",
    "                palette=\"viridis\", alpha=0.5)\n",
    "plt.legend(title=\"MedHouseVal\", bbox_to_anchor=(1.05, 1),\n",
    "           loc=\"upper left\")\n",
    "plt.title(\"Median house value depending of\\n their world location\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II - Recherche du modèle adéquat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Premiers essais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RandomForestClassifier\n",
    "\n",
    "modele_rf = RandomForestClassifier(\n",
    "    # il s’agit du nombre d’arbres dans la forêt\n",
    "    n_estimators=5,\n",
    "    # il s’agit du critère utilisé pour construire les arbres et séparer les branches des arbres\n",
    "    criterion='gini',\n",
    "    # il s’agit de la profondeur maximale des arbres utilisés (le nombre de niveaux dans l’arbre de décision)\n",
    "    max_depth=None,\n",
    "    # il s’agit du nombre d’échantillons minimal dans une feuille pour refaire une séparation\n",
    "    min_samples_split=2,\n",
    "    # il s’agit du nombre d’échantillons minimal pour créer une feuille\n",
    "    min_samples_leaf=1,\n",
    "    # il s’agit de la fraction du nombre total d’échantillon minimal pour créer une feuille\n",
    "    min_weight_fraction_leaf=0.0,\n",
    "    # il s’agit du nombre maximal de feuilles\n",
    "    max_leaf_nodes=None,\n",
    "    # il s’agit de la baisse minimale du critère d’impureté pour faire une séparation\n",
    "    min_impurity_decrease=0.0,\n",
    "    # paramètre pour utiliser du bootstrap, si il est à False, le même échantillon est pris pour chaque arbre\n",
    "    bootstrap=True,\n",
    "    # ??\n",
    "    oob_score=False,\n",
    "    # nombre de traitements à effectuer en parallèle\n",
    "    n_jobs=None,\n",
    "    # graine aléatoire\n",
    "    random_state=None,\n",
    "    # ??\n",
    "    verbose=0,\n",
    "    # ceci permet de repartir du résultat du dernier apprentissage pour faire l’apprentissage\n",
    "    warm_start=False,\n",
    "    # il s’agit des poids associés à chaque classe si cela a un sens\n",
    "    class_weight=None,\n",
    "    # ??\n",
    "    ccp_alpha=0.0,\n",
    "    # si vous voulez réduire le nombre d’observations dans vos échantillons bootstrap\n",
    "    max_samples=None,\n",
    ")\n",
    "\n",
    "modele_rf.fit(data, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#KNeighborsRegressor\n",
    "\n",
    "#Colonnes exclues pour le train\n",
    "KNeighborsRegressor_data = df.drop(columns=[target_name, \"AveOccup\", \"Population\", \"HouseAge\", \"AveBedrms\" , \"AveRooms\"])\n",
    "\n",
    "#Entrainement\n",
    "KNeighborsRegressor_model = KNeighborsRegressor()\n",
    "KNeighborsRegressor_model.fit(KNeighborsRegressor_data, target)\n",
    "\n",
    "target_predicted = KNeighborsRegressor_model.predict(KNeighborsRegressor_data)\n",
    "print(target[:5])\n",
    "print(target_predicted[:5])\n",
    "print(f\"Number of correct prediction: \"\n",
    "      f\"{(target[:5] == target_predicted[:5]).sum()} / 5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Modèles linéaires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test de tous les modèles linéaires\n",
    "\n",
    "#Nombre de tests par modèle\n",
    "attemps = 200\n",
    "\n",
    "def TestLinearModels(models):\n",
    "    \n",
    "    #Initialisation de la dataframe des resultats\n",
    "    result_df = pd.DataFrame(columns=[\"ModelName\",\"AvgScore\",\"MaxScore\",\"AvgExecTime\"])\n",
    "\n",
    "    for model in models:\n",
    "\n",
    "        #Affichage\n",
    "        model_name = model.__class__.__name__\n",
    "        print(f\"{model_name}\")\n",
    "\n",
    "        #Initialisation des listes\n",
    "        score_results = []\n",
    "        time_results = []\n",
    "        \n",
    "        for i in tqdm(range(attemps)):\n",
    "\n",
    "            #Demarrage du timer\n",
    "            start = time.time()\n",
    "\n",
    "            #Fit\n",
    "            model.fit(data_train, target_train)\n",
    "\n",
    "            #Calcul du score\n",
    "            score = model.score(data_test, target_test)\n",
    "\n",
    "            #Sauvegarde des resultats dans les listes\n",
    "            score_results.append(score)\n",
    "            time_results.append(time.time() - start)\n",
    "\n",
    "        #Calcul des stats\n",
    "        avg_score = round(np.average(score_results) * 100, 3)\n",
    "        max_score = round(np.max(score_results) * 100, 3)\n",
    "        avg_time = round(np.average(time_results), 3)\n",
    "\n",
    "        #Sauvegarde des resultats dans la dataframe\n",
    "        new_row = pd.DataFrame([[model_name, avg_score, max_score, avg_time]], columns=[\"ModelName\",\"AvgScore\",\"MaxScore\",\"AvgExecTime\"])\n",
    "        result_df = pd.concat([result_df, new_row])\n",
    "\n",
    "    #Affichage\n",
    "    print(f\"-\"*49, \"\\nResults :\")\n",
    "    print(result_df.to_string(index=False))\n",
    "    print(f\"-\"*49)\n",
    "\n",
    "#Call de la fonction\n",
    "TestLinearModels(linear_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Learning curves des modèles linéaires\n",
    "\n",
    "def linear_learnings_curves(\n",
    "    models,\n",
    "    data,\n",
    "    target\n",
    "):\n",
    "    plt.figure(1)\n",
    "    fig, graphs = plt.subplots(1, len(models), figsize=(5* len(models), 5))\n",
    "    n_jobs = -1\n",
    "    points_amount = 100\n",
    "    train_score_arr = []\n",
    "    test_scores_arr = []\n",
    "\n",
    "    for i in tqdm(range(len(models))):\n",
    "        graphs[i].set_title(models[i].__class__.__name__)\n",
    "        graphs[i].set_xlabel(\"Training set size\")\n",
    "        graphs[i].set_ylabel(\"Error\")\n",
    "        \n",
    "        train_sizes, train_scores, test_scores = learning_curve(\n",
    "        random_state=69,\n",
    "        estimator = models[i],\n",
    "        X=data,\n",
    "        y=target,\n",
    "        n_jobs=n_jobs,\n",
    "        train_sizes=np.linspace(0.1, 1, points_amount),\n",
    "        scoring=\"neg_mean_squared_error\"\n",
    "        )\n",
    "\n",
    "        train_scores_mean = -np.mean(train_scores, axis=1)\n",
    "        test_scores_mean = -np.mean(test_scores, axis=1)\n",
    "\n",
    "        train_score_arr.append(train_scores_mean)\n",
    "        test_scores_arr.append(test_scores_mean)\n",
    "\n",
    "    for i in range(len(train_score_arr)):\n",
    "        graphs[i].set_ylim(0,2)\n",
    "        graphs[i].plot(train_sizes, train_score_arr[i])\n",
    "        graphs[i].plot(train_sizes, test_scores_arr[i])\n",
    "        graphs[i].legend(labels=[\"train\", \"test\"], loc=\"lower right\")\n",
    "\n",
    "    return plt\n",
    "\n",
    "\n",
    "#Call de la fonction\n",
    "linear_learnings_curves(\n",
    "    linear_models,\n",
    "    data,\n",
    "    target\n",
    ")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) Ensembles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test de tous les modèles ensemblistes\n",
    "\n",
    "#Nombre de tests par modèle\n",
    "attemps = 10\n",
    "\n",
    "def TestEnsModels(models):\n",
    "    \n",
    "    #Initialisation de la dataframe des resultats\n",
    "    result_df = pd.DataFrame(columns=[\"ModelName\",\"AvgScore\",\"MaxScore\",\"AvgExecTime\"])\n",
    "\n",
    "    for model in models:\n",
    "\n",
    "        #Affichage\n",
    "        model_name = model.__class__.__name__\n",
    "        print(f\"{model_name}\")\n",
    "\n",
    "        #Initialisation des listes\n",
    "        score_results = []\n",
    "        time_results = []\n",
    "        \n",
    "        for i in tqdm(range(attemps)):\n",
    "\n",
    "            #Demarrage du timer\n",
    "            start = time.time()\n",
    "\n",
    "            #Fit\n",
    "            model.fit(data_train, target_train)\n",
    "\n",
    "            #Calcul du score\n",
    "            score = model.score(data_test, target_test)\n",
    "\n",
    "            #Sauvegarde des resultats dans les listes\n",
    "            score_results.append(score)\n",
    "            time_results.append(time.time() - start)\n",
    "\n",
    "        #Calcul des stats\n",
    "        avg_score = round(np.average(score_results) * 100, 3)\n",
    "        max_score = round(np.max(score_results) * 100, 3)\n",
    "        avg_time = round(np.average(time_results), 3)\n",
    "\n",
    "        #Sauvegarde des resultats dans la dataframe\n",
    "        new_row = pd.DataFrame([[model_name, avg_score, max_score, avg_time]], columns=[\"ModelName\",\"AvgScore\",\"MaxScore\",\"AvgExecTime\"])\n",
    "        result_df = pd.concat([result_df, new_row])\n",
    "\n",
    "    #Affichage\n",
    "    print(f\"-\"*62, \"\\nResults :\")\n",
    "    print(result_df.to_string(index=False))\n",
    "    print(f\"-\"*62)\n",
    "\n",
    "#Call de la fonction\n",
    "TestEnsModels(ens_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Learning curves des modèles ensemblistes\n",
    "\n",
    "def ens_learnings_curves(\n",
    "    models,\n",
    "    data,\n",
    "    target\n",
    "):\n",
    "    plt.figure(1)\n",
    "    fig, graphs = plt.subplots(1, len(models), figsize=(5* len(models), 5))\n",
    "    n_jobs = -1\n",
    "    points_amount = 10\n",
    "    train_score_arr = []\n",
    "    test_scores_arr = []\n",
    "\n",
    "    for i in tqdm(range(len(models))):\n",
    "        graphs[i].set_title(models[i].__class__.__name__)\n",
    "        graphs[i].set_xlabel(\"Training set size\")\n",
    "        graphs[i].set_ylabel(\"Error\")\n",
    "        \n",
    "        train_sizes, train_scores, test_scores = learning_curve(\n",
    "        random_state=69,\n",
    "        estimator = models[i],\n",
    "        X=data,\n",
    "        y=target,\n",
    "        n_jobs=n_jobs,\n",
    "        train_sizes=np.linspace(0.1, 1, points_amount),\n",
    "        scoring=\"neg_mean_squared_error\"\n",
    "        )\n",
    "\n",
    "        train_scores_mean = -np.mean(train_scores, axis=1)\n",
    "        test_scores_mean = -np.mean(test_scores, axis=1)\n",
    "\n",
    "        train_score_arr.append(train_scores_mean)\n",
    "        test_scores_arr.append(test_scores_mean)\n",
    "\n",
    "\n",
    "    for i in range(len(train_score_arr)):\n",
    "        graphs[i].set_ylim(0,2)\n",
    "        graphs[i].plot(train_sizes, train_score_arr[i])\n",
    "        graphs[i].plot(train_sizes, test_scores_arr[i])\n",
    "        graphs[i].legend(labels=[\"train\", \"test\"], loc=\"upper right\")\n",
    "\n",
    "    return plt\n",
    "\n",
    "#Call de la fonction\n",
    "ens_learnings_curves(\n",
    "    ens_models,\n",
    "    data,\n",
    "    target\n",
    ")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## III - Recherche des meilleurs hyperparamètres"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Recherche des meilleurs hyperparamètres pour le HistGradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fonction fit + score\n",
    "def fit_and_score(alg):\n",
    "    alg.fit(data_train, target_train)\n",
    "    print(\"R2 : \"+str(alg.score(data_test, target_test)*100))\n",
    "    return alg.score(data_test, target_test)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "82.85875163749014"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Modèle de base\n",
    "model = HistGradientBoostingRegressor(\n",
    "    random_state=69,\n",
    ")\n",
    "\n",
    "fit_and_score(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_iter': 280}\n",
      "83.91491564971824\n"
     ]
    }
   ],
   "source": [
    "#Recherche \"max_iter\"\n",
    "model = HistGradientBoostingRegressor(\n",
    "    random_state=69,\n",
    "    min_samples_leaf=20,\n",
    "    max_depth=12,\n",
    "    learning_rate=0.1,\n",
    ")\n",
    "\n",
    "parameters = {\n",
    "    'max_iter':range(10,501,10),\n",
    "}\n",
    "\n",
    "clf = GridSearchCV(estimator=model, param_grid=parameters)\n",
    "\n",
    "clf.fit(data_train, target_train)\n",
    "print(clf.best_params_)\n",
    "print(clf.score(data_test, target_test)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 18, 'min_samples_leaf': 40}\n",
      "84.069723920638\n"
     ]
    }
   ],
   "source": [
    "#Recherche \"min_samples_leaf\" & \"max_depth\"\n",
    "model = HistGradientBoostingRegressor(\n",
    "    random_state=69,\n",
    "    max_iter=280,\n",
    "    learning_rate=0.1,\n",
    ")\n",
    "\n",
    "parameters = {\n",
    "    'min_samples_leaf':range(10, 121, 10),\n",
    "    'max_depth':range(10,21,2),\n",
    "}\n",
    "\n",
    "clf = GridSearchCV(estimator=model, param_grid=parameters)\n",
    "\n",
    "clf.fit(data_train, target_train)\n",
    "print(clf.best_params_)\n",
    "print(clf.score(data_test, target_test)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25.067762567270965 +- 28.42309588816349\n"
     ]
    }
   ],
   "source": [
    "#Final HistGradientBoostingRegressor parameters\n",
    "model = HistGradientBoostingRegressor(\n",
    "    random_state=69,\n",
    "    max_depth=18,\n",
    "    min_samples_leaf=40,\n",
    "    max_iter=280,\n",
    "    learning_rate=0.1,\n",
    "    warm_start=True\n",
    ")\n",
    "\n",
    "fit_and_score(model)\n",
    "\n",
    "r = np.absolute(model.predict(data) - target)*100\n",
    "\n",
    "print(str(np.mean(r)) + \" +- \" + str(np.std(r)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Recherche des meilleurs hyperparamètres pour le AdaBoostRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "84.58150365307209"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Modèle de base\n",
    "m = AdaBoostRegressor(random_state=69, base_estimator=model)\n",
    "fit_and_score(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'learning_rate': 0.1, 'n_estimators': 40}\n",
      "84.81381972890627\n"
     ]
    }
   ],
   "source": [
    "#Recherche \"n_estimators\" & \"learning_rate\"\n",
    "m = AdaBoostRegressor(random_state=69,\n",
    "                      base_estimator=model,\n",
    "                      learning_rate=0.1)\n",
    "\n",
    "parameters = {\n",
    "    'n_estimators':range(40, 51, 5),\n",
    "    'learning_rate':[0.1, 1],\n",
    "}\n",
    "\n",
    "clf = GridSearchCV(estimator=m, param_grid=parameters)\n",
    "\n",
    "clf.fit(data_train, target_train)\n",
    "print(clf.best_params_)\n",
    "print(clf.score(data_test, target_test)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 : 85.1542366577762\n",
      "11.952681698961994 +- 17.70402581658711\n"
     ]
    }
   ],
   "source": [
    "#Final Results Ada(Hist())\n",
    "final_model = AdaBoostRegressor(random_state=69, learning_rate=1,n_estimators=115, base_estimator=HistGradientBoostingRegressor(learning_rate=0.1, max_iter=1000, max_depth=7, warm_start=True, max_leaf_nodes=60, random_state=69,  max_bins=255))\n",
    "\n",
    "fit_and_score(final_model)\n",
    "\n",
    "r = np.absolute(final_model.predict(data) - target)*100\n",
    "\n",
    "print(str(np.mean(r)) + \" +- \" + str(np.std(r)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IV - Sauvegarde de l'IA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                           ModelName     Score\n",
      "0  AdaBoostRegressor(HistGradientBoostingRegresso...  0.851542\n"
     ]
    }
   ],
   "source": [
    "#Sauvegarde de l'IA\n",
    "\n",
    "def AI_train_and_save(model):\n",
    "    \n",
    "    #Initialisation de la dataframe des resultats\n",
    "    result_df = pd.DataFrame(columns=[\"ModelName\",\"Score\"])\n",
    "\n",
    "    #Affichage\n",
    "    model_name = model.__class__.__name__ + \"(\" +  model.base_estimator.__class__.__name__ + \"())\"\n",
    "\n",
    "    #Fit\n",
    "    model.fit(data_train, target_train)\n",
    "\n",
    "    #Calcul du score\n",
    "    score = model.score(data_test, target_test)*100\n",
    "\n",
    "    #Sauvegarde des resultats dans la dataframe\n",
    "    new_row = pd.DataFrame([[model_name, score]], columns=[\"ModelName\",\"Score\"])\n",
    "    result_df = pd.concat([result_df, new_row])\n",
    "\n",
    "    #Affichage du score\n",
    "    print(result_df)\n",
    "\n",
    "    #Sauvegarde de l'IA\n",
    "    with open(f\"{score}.joblib\", \"wb\") as fo:\n",
    "        joblib.dump(model, fo)\n",
    "\n",
    "#Call de la fonction\n",
    "AI_train_and_save(final_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## V - Test de l'IA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Predicted  Original          Ecart\n",
      "0       4.432357     4.526    9364.269210\n",
      "1       3.630886     3.585    4588.646308\n",
      "2       4.582870     3.521  106187.002778\n",
      "3       3.466137     3.413    5313.689268\n",
      "4       3.315778     3.422   10622.246697\n",
      "...          ...       ...            ...\n",
      "20635   0.768587     0.781    1241.282860\n",
      "20636   0.828364     0.771    5736.406130\n",
      "20637   0.897097     0.923    2590.302024\n",
      "20638   0.898776     0.847    5177.629022\n",
      "20639   0.874969     0.894    1903.095152\n",
      "\n",
      "[20640 rows x 3 columns]\n",
      "0.5284826749663019\n",
      "11952.681698961995\n",
      "8594.969820317034\n"
     ]
    }
   ],
   "source": [
    "#Test\n",
    "\n",
    "#Chargement de l'IA sauvegardée\n",
    "with open(\"0.8515423665777619.joblib\", \"rb\") as fo:\n",
    "    cf = joblib.load(fo)\n",
    "\n",
    "#Predict\n",
    "predicted = cf.predict(data)\n",
    "d = {'Predicted': predicted, 'Original': target, 'Ecart': np.absolute(predicted-target)*100000}\n",
    "\n",
    "#Stockage et affichage du resultat\n",
    "supa_resulto_dataframu = pd.DataFrame(data=d)\n",
    "print(supa_resulto_dataframu)\n",
    "\n",
    "#Affichage des stats\n",
    "print(np.min(supa_resulto_dataframu[\"Ecart\"]))\n",
    "print(np.average(supa_resulto_dataframu[\"Ecart\"]))\n",
    "print(np.median(supa_resulto_dataframu[\"Ecart\"]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d9cca3b5787ed073d3b77f03b758985ef55479ddb50c5b8f16161c9ada7875b4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
