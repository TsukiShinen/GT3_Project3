{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports & Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports\n",
    "\n",
    "import os\n",
    "import time\n",
    "import joblib\n",
    "from tqdm import tqdm\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.datasets import _california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import *\n",
    "from sklearn.ensemble import *\n",
    "\n",
    "from sklearn.model_selection import learning_curve\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "#Settings\n",
    "plt.style.use('dark_background')\n",
    "\n",
    "#Colonnes du dataset\n",
    "\"\"\"\n",
    "- MedInc        median income in block group\n",
    "- HouseAge      median house age in block group\n",
    "- AveRooms      average number of rooms per household\n",
    "- AveBedrms     average number of bedrooms per household\n",
    "- Population    block group population\n",
    "- AveOccup      average number of household members\n",
    "- Latitude      block group latitude\n",
    "- Longitude     block group longitude\n",
    "- MedHouseVal   median house value\n",
    "\"\"\"\n",
    "\n",
    "#Creation du dataframe avec le dataset\n",
    "dataset = _california_housing.fetch_california_housing(as_frame=True)\n",
    "df = dataset.frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Variables\n",
    "\n",
    "#Definition de la target\n",
    "target_name = \"MedHouseVal\"\n",
    "target = df[target_name]\n",
    "\n",
    "#Colonnes exclues pour le test\n",
    "columns_to_drop = [\n",
    "    target_name, \n",
    "    # \"Population\", \n",
    "    # \"AveOccup\", \n",
    "    # \"AveBedrms\", \n",
    "    # \"HouseAge\", \n",
    "    # \"AveRooms\"\n",
    "]\n",
    "data = df.drop(columns=columns_to_drop)\n",
    "\n",
    "#Modeles a tester\n",
    "\n",
    "linear_models = [\n",
    "    LinearRegression(),\n",
    "    Ridge(),\n",
    "    RidgeCV(),\n",
    "    SGDRegressor(),\n",
    "    Lasso(),\n",
    "]\n",
    "\n",
    "models = [\n",
    "    AdaBoostRegressor(),  \n",
    "    BaggingRegressor(n_jobs=-1), \n",
    "    ExtraTreesRegressor(n_jobs=-1), \n",
    "    GradientBoostingRegressor(), \n",
    "    RandomForestRegressor(n_jobs=-1), \n",
    "    HistGradientBoostingRegressor()\n",
    "]\n",
    "\n",
    "boost_and_bag_models = [\n",
    "    #AdaBoostRegressor(base_estimator=BaggingRegressor(n_jobs=-1)),\n",
    "    #AdaBoostRegressor(base_estimator=ExtraTreesRegressor(n_jobs=-1)),\n",
    "    #AdaBoostRegressor(base_estimator=GradientBoostingRegressor()),\n",
    "    #AdaBoostRegressor(base_estimator=RandomForestRegressor(n_jobs=-1)),\n",
    "    AdaBoostRegressor(random_state=69, learning_rate=1,n_estimators=115, base_estimator=HistGradientBoostingRegressor(learning_rate=0.1, max_iter=1000, max_depth=7, warm_start=True, max_leaf_nodes=None, random_state=69,  max_bins=255)),\n",
    "\n",
    "    #BaggingRegressor(base_estimator=BaggingRegressor(n_jobs=-1)),\n",
    "    #BaggingRegressor(base_estimator=ExtraTreesRegressor(n_jobs=-1)),\n",
    "    #BaggingRegressor(base_estimator=GradientBoostingRegressor()),\n",
    "    #BaggingRegressor(base_estimator=RandomForestRegressor(n_jobs=-1)),\n",
    "    #BaggingRegressor(base_estimator=HistGradientBoostingRegressor()),\n",
    "]\n",
    "\n",
    "#Nombre de trainings par modele\n",
    "attemps = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 - Début de l'analyse des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Infos du dataset\n",
    "\n",
    "print(dataset.DESCR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Heatmap\n",
    "\n",
    "data = df.drop(columns=[\"Latitude\", \"Longitude\"])\n",
    "plt.figure(figsize=(12,7))\n",
    "sns.heatmap(data.corr(),cbar=True,annot=True,cmap='Blues')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prix moyen en fonction de l'age des maisons\n",
    "\n",
    "sns.lineplot(df,\n",
    "                x=\"HouseAge\", y=\"MedHouseVal\", alpha=0.5)\n",
    "plt.title(\"MedHouseVal based on HouseAge\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prix moyen en fonction du nombre de pièces\n",
    "\n",
    "sns.lineplot(df,\n",
    "                x=\"AveBedrms\", y=\"MedHouseVal\", alpha=0.5)\n",
    "plt.title(\"MedHouseVal based on AveRooms\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prix moyen en fonction de la localisation géographique\n",
    "\n",
    "sns.scatterplot(df,\n",
    "                x=\"Longitude\", y=\"Latitude\",\n",
    "                size=\"MedHouseVal\", hue=\"MedHouseVal\",\n",
    "                palette=\"viridis\", alpha=0.5)\n",
    "plt.legend(title=\"MedHouseVal\", bbox_to_anchor=(1.05, 1),\n",
    "           loc=\"upper left\")\n",
    "plt.title(\"Median house value depending of\\n their world location\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 - Recherche du modèle adéquat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RandomForestClassifier\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.01, random_state=42)\n",
    "\n",
    "modele_rf = RandomForestClassifier(\n",
    "    # il s’agit du nombre d’arbres dans la forêt\n",
    "    n_estimators=5,\n",
    "    # il s’agit du critère utilisé pour construire les arbres et séparer les branches des arbres\n",
    "    criterion='gini',\n",
    "    # il s’agit de la profondeur maximale des arbres utilisés (le nombre de niveaux dans l’arbre de décision)\n",
    "    max_depth=None,\n",
    "    # il s’agit du nombre d’échantillons minimal dans une feuille pour refaire une séparation\n",
    "    min_samples_split=2,\n",
    "    # il s’agit du nombre d’échantillons minimal pour créer une feuille\n",
    "    min_samples_leaf=1,\n",
    "    # il s’agit de la fraction du nombre total d’échantillon minimal pour créer une feuille\n",
    "    min_weight_fraction_leaf=0.0,\n",
    "    # il s’agit du nombre maximal de feuilles\n",
    "    max_leaf_nodes=None,\n",
    "    # il s’agit de la baisse minimale du critère d’impureté pour faire une séparation\n",
    "    min_impurity_decrease=0.0,\n",
    "    # paramètre pour utiliser du bootstrap, si il est à False, le même échantillon est pris pour chaque arbre\n",
    "    bootstrap=True,\n",
    "    # ??\n",
    "    oob_score=False,\n",
    "    # nombre de traitements à effectuer en parallèle\n",
    "    n_jobs=None,\n",
    "    # graine aléatoire\n",
    "    random_state=None,\n",
    "    # ??\n",
    "    verbose=0,\n",
    "    # ceci permet de repartir du résultat du dernier apprentissage pour faire l’apprentissage\n",
    "    warm_start=False,\n",
    "    # il s’agit des poids associés à chaque classe si cela a un sens\n",
    "    class_weight=None,\n",
    "    # ??\n",
    "    ccp_alpha=0.0,\n",
    "    # si vous voulez réduire le nombre d’observations dans vos échantillons bootstrap\n",
    "    max_samples=None,\n",
    ")\n",
    "\n",
    "modele_rf.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#KNeighborsRegressor\n",
    "\n",
    "#Colonnes exclues pour le train\n",
    "data = df.drop(columns=[target_name, \"AveOccup\", \"Population\", \"HouseAge\", \"AveBedrms\" , \"AveRooms\"])\n",
    "\n",
    "#Entrainement\n",
    "model = KNeighborsRegressor()\n",
    "model.fit(data, target)\n",
    "\n",
    "target_predicted = model.predict(data)\n",
    "print(target[:5])\n",
    "print(target_predicted[:5])\n",
    "print(f\"Number of correct prediction: \"\n",
    "      f\"{(target[:5] == target_predicted[:5]).sum()} / 5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b37f6842cfa5693682ca177646b86562e7e6680399d6aa97975ae5063d95e764"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
